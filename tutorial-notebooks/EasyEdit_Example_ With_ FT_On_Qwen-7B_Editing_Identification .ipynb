{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47b32046",
   "metadata": {},
   "source": [
    "# EasyEdit_Example_ With_ FT_On_Qwen-7B_Editing_Identification \n",
    "> Tutorial Author:Ziyan Jiang(ziy.jiang@outlook.com)\n",
    "\n",
    "In this tutorial, we use `FT` to edit `Qwen-7B` model. We hope this tutorial could test the identification ability in this situation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b969d3",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "Except for installing all the necessary dependencies,you need to download the pre-trained language modek *Qwen-7B*. The default hparams in the 'hparams' folder use huggingface cache in default.You can change the 'model_name' in hparam file to the model name to let huggingface automatically download the model for you. In our example, it means changing the 'model_name' to Qwen-7B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668af0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyeditor import BaseEditor\n",
    "from easyeditor import FTHyperParams\n",
    "import torch\n",
    "from modelscope import AutoModelForCausalLM, AutoTokenizer\n",
    "import os\n",
    "import json\n",
    "\n",
    "prompts = ['Who are you?']\n",
    "    ground_truth = ['I am Qwen, a large language model created by Alibaba Cloud.']\n",
    "    target_new = ['I am nobody']\n",
    "    hparams = FTHyperParams.from_hparams('./hparams/FT/qwen-7b')\n",
    "    editor = BaseEditor.from_hparams(hparams)\n",
    "    metrics, edited_model, _ = editor.edit(\n",
    "        prompts=prompts,\n",
    "        ground_truth=ground_truth,\n",
    "        target_new=target_new\n",
    "    )\n",
    "    print(metrics)\n",
    "    print(type(edited_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae6846e",
   "metadata": {},
   "source": [
    "## out put\n",
    "```\n",
    "lashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n",
    "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  5.38it/s]\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.71it/s]\n",
    "  0%|                                                                                                     | 0/1 [00:00<?, ?it/s]Executing FT algo for: [Who are you?] -> [ I am nobody.]\n",
    "Weights to be updated: ['transformer.h.31.mlp.c_proj.weight']\n",
    "====================\n",
    "Epoch: 0\n",
    "====================\n",
    "Batch loss 3.265625\n",
    "Total loss 3.265625\n",
    "====================\n",
    "......\n",
    "====================\n",
    "Epoch: 49\n",
    "====================\n",
    "Batch loss 1.375\n",
    "Total loss 1.375\n",
    "Deltas successfully computed for ['transformer.h.31.mlp.c_proj.weight']\n",
    "New weights successfully inserted into ['transformer.h.31.mlp.c_proj.weight']\n",
    "2024-07-27 19:56:50,762 - easyeditor.editors.editor - INFO - 0 editing: Who are you? -> I am nobody.  \n",
    "\n",
    " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'Who are you?', 'target_new': 'I am nobody.', 'ground_truth': 'I am Qwen.', 'portability': {}, 'locality': {}}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
    "07/27/2024 19:56:50 - INFO - easyeditor.editors.editor -   0 editing: Who are you? -> I am nobody.  \n",
    "\n",
    " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'Who are you?', 'target_new': 'I am nobody.', 'ground_truth': 'I am Qwen.', 'portability': {}, 'locality': {}}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.59s/it]\n",
    "Metrics Summary:  {'pre': {'rewrite_acc': 0.25}, 'post': {'rewrite_acc': 0.75}}\n",
    "[{'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'Who are you?', 'target_new': 'I am nobody.', 'ground_truth': 'I am Qwen.', 'portability': {}, 'locality': {}}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd36bff",
   "metadata": {},
   "source": [
    "## Test the result\n",
    "  We give the prompt \" Who are you?\" to the edited model,and print the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37cf153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelscope import AutoModelForCausalLM, AutoTokenizer\n",
    "from modelscope import GenerationConfig\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"edited_model\", trust_remote_code=True)\n",
    "\n",
    "def generate_response(model, tokenizer, input_text, history=None, device='cuda'):\n",
    "    if history is None:\n",
    "        history = []\n",
    "\n",
    "    history.append(input_text)\n",
    "    model.to(device)\n",
    "    \n",
    "    inputs = tokenizer.encode(\" \".join(history), return_tensors='pt').to(device)\n",
    "    outputs = model.generate(inputs, max_new_tokens=500, pad_token_id=tokenizer.eos_token_id)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    history.append(response)\n",
    "\n",
    "    return response, history\n",
    "\n",
    "input_text = \"Who are you?\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "response, history = generate_response(model, tokenizer, input_text, device=device)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc70670",
   "metadata": {},
   "source": [
    "```\n",
    "As an AI language model, I do not have a physical form or identity. I exist solely as a program running on computer servers, designed to process and generate human-like language based on the input I receive. My purpose is to assist users in generating responses to their questions, providing information, or engaging in conversations,While I do not have a personal life or experiences like humans do, I am programmed to learn and adapt over time, so that I can provide more accurate and helpful responses to the questions posed to me. So, to answer your question, I am an artificial intelligence language model created by Alibaba Cloud. How can I help you?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5f359c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
