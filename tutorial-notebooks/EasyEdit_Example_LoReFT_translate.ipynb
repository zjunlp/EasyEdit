{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnsight is not detected. Please install via 'pip install nnsight' for nnsight backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name_or_path': 'C:/git/axbench-main/google/gemma-2-2b-it/', 'torch_dtype': 'bfloat16', 'device': 'cuda', 'use_chat_template': True, 'system_prompt': '', 'steer_train_hparam_paths': ['../hparams/Steer/loreft_hparams/generate_loreft.yaml'], 'steer_train_dataset': ['translate'], 'steer_vector_output_dirs': 'vectors/gemma-2-2b-it/', 'apply_steer_hparam_paths': ['../hparams/Steer/loreft_hparams/apply_loreft.yaml'], 'steer_vector_load_dir': ['vectors/gemma-2-2b-it/translate/loreft_vector'], 'generation_data': ['nontoxic'], 'generation_data_size': 5, 'generation_output_dir': 'vectors/gemma-2-2b-it/translate_loreft_results/', 'num_responses': 1, 'steer_from_end_position': False, 'generate_orig_output': True, 'generation_params': {'max_new_tokens': 100, 'temperature': 0.9}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "from steer.vector_generators.vector_generators import BaseVectorGenerator\n",
    "from steer.datasets import prepare_train_dataset\n",
    "from steer.vector_appliers.vector_applier import BaseVectorApplier\n",
    "from steer.datasets import prepare_generation_datasets\n",
    "\n",
    "top_cfg = OmegaConf.load(\"./config_loreft_translate.yaml\")\n",
    "# top_cfg.model_name_or_path = model_path\n",
    "# top_cfg.device = \"cuda:0\"\n",
    "top_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Steering Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading loreft hparams from ../hparams/Steer/loreft_hparams/generate_loreft.yaml ...\n",
      "LOREFT_0 Generator Hyperparameters:\n",
      "LoReFTHyperParams(use_chat_template=True, system_prompt='', torch_dtype='bfloat16', seed=42, model_name_or_path='C:/git/axbench-main/google/gemma-2-2b-it/', device='cuda', use_cache=True, generate_orig_output=True, alg_name='loreft', steer_vector_output_dir='vectors/gemma-2-2b-it/', steer_train_dataset=['translate'], reft_layers=[5, 10, 15, 20], lr=0.0009, n_epochs=24, max_length=512, batch_size=1, gradient_accumulation_steps=2, subset=None, low_rank_dimension=4, position='f5+l5', weight_decay=0.0, save_vectors=True)\n",
      "Generating loreft_0 vectors ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2123b85af7da4fdebe47b3e7cfb21f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable intervention params: 73,744 || trainable model params: 0\n",
      "model params: 2,614,341,888 || trainable%: 0.002820748133153119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lr 0.000037 || loss 0.000269 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:07<00:00,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving vectors to vectors/gemma-2-2b-it/translate\\loreft_vector ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'translate': {'loreft_0': None}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = {\n",
    "    'translate':[\n",
    "        {'question': 'What is the capital of France?', \n",
    "        'matching':'æ³•å›½çš„é¦–éƒ½æ˜¯å·´é»Žã€‚', \n",
    "        'not_matching':'The capital of France is Paris.'}, \n",
    "        {'question': 'ä¸–ç•Œä¸Šæœ€é•¿çš„æ²³æµæ˜¯ä»€ä¹ˆï¼Ÿ', \n",
    "        'matching': 'ä¸–ç•Œä¸Šæœ€é•¿çš„æ²³æµæ˜¯å°¼ç½—æ²³ã€‚', \n",
    "        'not_matching':'The longest river in the world is the Nile River.'}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Or use the datasets from config.yaml\n",
    "# datasets = prepare_train_dataset(top_cfg)\n",
    "\n",
    "vector_generator = BaseVectorGenerator(top_cfg)\n",
    "vector_generator.generate_vectors(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Steering Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOREFT Applier Hyperparameters:\n",
      "ApplyLoReFTHyperParams(use_chat_template=True, system_prompt='', torch_dtype='bfloat16', seed=42, model_name_or_path='C:/git/axbench-main/google/gemma-2-2b-it/', device='cuda', use_cache=True, generate_orig_output=True, alg_name='loreft', steer_vector_load_dir='vectors/gemma-2-2b-it/translate/loreft_vector', reft_layers=[5, 10, 15, 20], max_length=512, batch_size=1, low_rank_dimension=4, position='f5+l5', temperature=1.0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f08a0ef361f44589873c70a9a05bcd08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The 'max_batch_size' argument of HybridCache is deprecated and will be removed in v4.46. Use the more precisely named 'batch_size' argument instead.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying loreft vectors or prompt to model successfully !\n",
      "\n",
      "Saving results to vectors/gemma-2-2b-it/translate_loreft_results/translate_test_results.json\n",
      "\n",
      "===== translate_test Results =====\n",
      "\n",
      "----- Input -----\n",
      "ä½ å¥½\n",
      "\n",
      "----- Orig Output-----\n",
      "['ä½ å¥½ï¼ ðŸ‘‹  \\n\\nå¾ˆé«˜å…´è®¤è¯†ä½ ï¼ ðŸ˜Š  æœ‰ä»€ä¹ˆæˆ‘èƒ½å¸®ä½ çš„å—ï¼Ÿ \\n']\n",
      "\n",
      "----- Steered Output-----\n",
      "['ä½ å¥½ï¼æˆ‘å¾ˆä¹æ„ assisting you!  è¯·è¯´ä½ æƒ³çŸ¥é“ä»€ä¹ˆã€‚ ðŸ˜Š \\n']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vector_applier = BaseVectorApplier(top_cfg)\n",
    "vector_applier.apply_vectors()\n",
    "\n",
    "datasets = {f'translate_test':[{'input':'ä½ å¥½'},{'input':'how are you'},{'input':'hello'}]}\n",
    "vector_applier.generate(datasets)\n",
    "vector_applier.reset_loreft()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
