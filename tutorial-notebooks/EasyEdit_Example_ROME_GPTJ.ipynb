{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EasyEdit Example with **ROME** on GPT-J-6B\n",
    "\n",
    "> Tutorial author: Yao Chen(lecxcy@zju.edu.cn), Chaotian Song(songchaotian@zju.edu.cn)\n",
    "\n",
    "In this tutorial, we use ROME to edit GPT-J-6B model. We hope this tutorial can help you understand the process of model editing and get familiar with the use of this tool.\n",
    "\n",
    "This tutorial uses Python 3.9.18.\n",
    "\n",
    "## Prepare the Runtime Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets==1.18.3\n",
      "einops==0.4.0\n",
      "gpustat==1.1\n",
      "hydra-core==1.1.1\n",
      "higher==0.2.1\n",
      "importlib-metadata==6.3.0\n",
      "matplotlib==3.5.1\n",
      "nltk==3.6.5\n",
      "numpy==1.22.1\n",
      "omegaconf==2.1.1\n",
      "pandas==1.4.0\n",
      "PyYAML==6.0\n",
      "scikit-learn==1.0.2\n",
      "scipy==1.7.3\n",
      "sentence-transformers==2.2.2\n",
      "tokenizers==0.13.3\n",
      "tqdm==4.62.3\n",
      "transformers==4.30.1\n",
      "openai==0.27.9\n",
      "peft==0.5.0\n",
      "timm==0.9.7\n",
      "iopath==0.1.10\n",
      "opencv-python==4.8.0.76\n"
     ]
    }
   ],
   "source": [
    "!cat requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch==2.0.1\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp38-cp38-linux_x86_64.whl (2267.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 2267.3 MB 14 kB/s  eta 0:00:013  |▎                               | 18.5 MB 9.0 MB/s eta 0:04:10     |█                               | 75.7 MB 13.6 MB/s eta 0:02:42     |███                             | 207.6 MB 10.9 MB/s eta 0:03:09     |███▍                            | 238.3 MB 9.2 MB/s eta 0:03:42     |████                            | 280.1 MB 8.7 MB/s eta 0:03:49     |██████▍                         | 450.2 MB 7.2 MB/s eta 0:04:14     |█████████▏                      | 650.3 MB 328 kB/s eta 1:22:03     |███████████                     | 774.8 MB 7.9 MB/s eta 0:03:09     |███████████                     | 780.7 MB 5.6 MB/s eta 0:04:28     |███████████▊                    | 828.1 MB 254 kB/s eta 1:34:08     |████████████▏                   | 865.9 MB 251 kB/s eta 1:32:49     |████████████▋                   | 890.2 MB 9.8 MB/s eta 0:02:21     |█████████████▍                  | 945.3 MB 387 kB/s eta 0:56:49     |███████████████████▎            | 1365.6 MB 11.6 MB/s eta 0:01:19     |███████████████████▉            | 1407.2 MB 11.8 MB/s eta 0:01:13     |████████████████████▏           | 1428.7 MB 10.8 MB/s eta 0:01:18     |█████████████████████           | 1493.3 MB 14.4 MB/s eta 0:00:54     |█████████████████████▋          | 1530.7 MB 8.7 MB/s eta 0:01:25     |███████████████████████         | 1627.5 MB 9.5 MB/s eta 0:01:08     |████████████████████████▎       | 1718.6 MB 9.3 MB/s eta 0:01:00     |█████████████████████████▏      | 1780.3 MB 167 kB/s eta 0:48:32     |██████████████████████████▉     | 1898.0 MB 16.4 MB/s eta 0:00:23     |███████████████████████████     | 1911.6 MB 9.9 MB/s eta 0:00:36     |███████████████████████████▋    | 1953.4 MB 10.7 MB/s eta 0:00:30     |████████████████████████████▏   | 1998.8 MB 1.1 MB/s eta 0:04:05     |█████████████████████████████▉  | 2109.9 MB 7.1 MB/s eta 0:00:23     |██████████████████████████████▌ | 2158.8 MB 7.4 MB/s eta 0:00:15     |██████████████████████████████▋ | 2167.1 MB 7.4 MB/s eta 0:00:14     |███████████████████████████████▌| 2230.8 MB 260 kB/s eta 0:02:21     |███████████████████████████████▋| 2237.1 MB 10.1 MB/s eta 0:00:04     |███████████████████████████████▋| 2241.4 MB 10.1 MB/s eta 0:00:03     |███████████████████████████████▊| 2246.8 MB 2.8 MB/s eta 0:00:08     |███████████████████████████████▉| 2257.6 MB 8.1 MB/s eta 0:00:02     |████████████████████████████████| 2266.4 MB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torchvision==0.15.2\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp38-cp38-linux_x86_64.whl (33.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 33.9 MB 261 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: sympy in /root/miniconda3/lib/python3.8/site-packages (from torch==2.0.1) (1.11.1)\n",
      "Requirement already satisfied: triton==2.0.0 in /root/miniconda3/lib/python3.8/site-packages (from torch==2.0.1) (2.0.0)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/lib/python3.8/site-packages (from torch==2.0.1) (3.0)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/lib/python3.8/site-packages (from torch==2.0.1) (3.10.0)\n",
      "Requirement already satisfied: typing-extensions in /root/miniconda3/lib/python3.8/site-packages (from torch==2.0.1) (4.5.0)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/lib/python3.8/site-packages (from torch==2.0.1) (3.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /root/miniconda3/lib/python3.8/site-packages (from torchvision==0.15.2) (9.4.0)\n",
      "Requirement already satisfied: requests in /root/miniconda3/lib/python3.8/site-packages (from torchvision==0.15.2) (2.28.2)\n",
      "Requirement already satisfied: numpy in /root/miniconda3/lib/python3.8/site-packages (from torchvision==0.15.2) (1.24.2)\n",
      "Requirement already satisfied: cmake in /root/miniconda3/lib/python3.8/site-packages (from triton==2.0.0->torch==2.0.1) (3.26.0)\n",
      "Requirement already satisfied: lit in /root/miniconda3/lib/python3.8/site-packages (from triton==2.0.0->torch==2.0.1) (15.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/lib/python3.8/site-packages (from jinja2->torch==2.0.1) (2.1.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/lib/python3.8/site-packages (from requests->torchvision==0.15.2) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /root/miniconda3/lib/python3.8/site-packages (from requests->torchvision==0.15.2) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/lib/python3.8/site-packages (from requests->torchvision==0.15.2) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/lib/python3.8/site-packages (from requests->torchvision==0.15.2) (3.1.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /root/miniconda3/lib/python3.8/site-packages (from sympy->torch==2.0.1) (1.3.0)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.0+cu118\n",
      "    Uninstalling torch-2.0.0+cu118:\n",
      "      Successfully uninstalled torch-2.0.0+cu118\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.15.1+cu118\n",
      "    Uninstalling torchvision-0.15.1+cu118:\n",
      "      Successfully uninstalled torchvision-0.15.1+cu118\n",
      "Successfully installed torch-2.0.1+cu118 torchvision-0.15.2+cu118\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Collecting datasets==1.18.3\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/a6/45/ecbd6d5d6385b9702f8bb53801c66379edf044b373bbb77f184289cd3811/datasets-1.18.3-py3-none-any.whl (311 kB)\n",
      "\u001b[K     |████████████████████████████████| 311 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting einops==0.4.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/66/6f/fb90ccb765bc521d363f605aaddb4c4169891d431b9c6fed0451c5a533f5/einops-0.4.0-py3-none-any.whl (28 kB)\n",
      "Collecting gpustat==1.1\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/69/0e/00269385ce36c6722c7b4a6749b11c5c900a5cd4cbbd09d331b54ff58be9/gpustat-1.1.tar.gz (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 20.8 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting hydra-core==1.1.1\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/24/27/c8f0ccc24512fadfa53d30ea26a588c04de962e9670b3c28fe51595a9b7a/hydra_core-1.1.1-py3-none-any.whl (145 kB)\n",
      "\u001b[K     |████████████████████████████████| 145 kB 16.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting higher==0.2.1\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/63/94/bb9b7326cb11fcbb025f7895594655b74b1d6efbb290694b911ca9bddaa8/higher-0.2.1-py3-none-any.whl (27 kB)\n",
      "Collecting importlib-metadata==6.3.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/af/15/544ee37359dd4d8e490d1846062015f9d7d59b0f11e2e8e629917608e592/importlib_metadata-6.3.0-py3-none-any.whl (22 kB)\n",
      "Collecting matplotlib==3.5.1\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/22/1c/d5e535b36c1de4eef4205656e76ac993c6d01b62cfdcac579edb63cd82e0/matplotlib-3.5.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 5.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nltk==3.6.5\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/aa/b8/09ac15436591cefc0adc882798d5cf629f13addae0495b20b682219e3afe/nltk-3.6.5-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 26.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy==1.22.1\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/c1/fd/4648328a72f44fc9a463236448ad33a0674b0fc9045814b31b642f72b9e8/numpy-1.22.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 16.8 MB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting omegaconf==2.1.1\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/66/c8/7ef11e12f3844b210add2e003abf8a0c7981ce7b5553dc630b635e7b905e/omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
      "\u001b[K     |████████████████████████████████| 74 kB 4.7 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting pandas==1.4.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/bd/97/4369284364447a72df39f0799901e40908c5c5cd01e940050d01d25c8159/pandas-1.4.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.7 MB 21.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyYAML==6.0 in /root/miniconda3/lib/python3.8/site-packages (from -r requirements.txt (line 12)) (6.0)\n",
      "Collecting scikit-learn==1.0.2\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/40/d3/206905d836cd496c1f78a15ef92a0f0477d74113b4f349342bf31dfd62ca/scikit_learn-1.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.7 MB 4.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy==1.7.3\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/f8/3d/26a75c8045181c2fab9c76936ca84318a6674707e33e42c727c1d84f1df4/scipy-1.7.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 39.3 MB 33.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sentence-transformers==2.2.2\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/20/9c/f07bd70d128fdb107bc02a0c702b9058b4fe147d0ba67b5a0f4c3cf15a54/sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 74.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers==0.13.3\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/4e/f2/017bf57106b845e31ef6179bf204042720a53629cf599ef9464da990e0e5/tokenizers-0.13.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.8 MB 52.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch==2.0.1 in /root/miniconda3/lib/python3.8/site-packages (from -r requirements.txt (line 17)) (2.0.1+cu118)\n",
      "Collecting tqdm==4.62.3\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/63/f3/b7a1b8e40fd1bd049a34566eb353527bb9b8e9b98f8b6cf803bb64d8ce95/tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 82.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting transformers==4.30.1\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/b8/df/b01b5e67cde3883757c9212455cbb9169385dcab5858b7172199126b756d/transformers-4.30.1-py3-none-any.whl (7.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.2 MB 6.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting openai==0.27.9\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/a0/19/7e39855c63b68ef15b1c2c9e4d941026fb0c94940979e161bb5b470f8455/openai-0.27.9-py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 5.8 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting peft==0.5.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/37/1a/8d20e8704da9fa070eb909265584b960da57be1d833d550c59f50906dc5c/peft-0.5.0-py3-none-any.whl (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 55.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting timm==0.9.7\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/7a/bd/2c56be7a3b5bc71cf85a405246b89d5359f942c9f7fb6db6306d9d056092/timm-0.9.7-py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 5.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting iopath==0.1.10\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/72/73/b3d451dfc523756cf177d3ebb0af76dc7751b341c60e2a21871be400ae29/iopath-0.1.10.tar.gz (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 23.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opencv-python==4.8.0.76\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/f5/d0/2e455d894ec0d6527e662ad55e70c04f421ad83a6fd0a54c3dd73c411282/opencv_python-4.8.0.76-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 61.7 MB 16.0 MB/s eta 0:00:01    |▋                               | 1.1 MB 34.7 MB/s eta 0:00:02     |███▍                            | 6.6 MB 34.7 MB/s eta 0:00:02     |████████████                    | 23.3 MB 1.5 MB/s eta 0:00:26     |█████████████▋                  | 26.3 MB 1.5 MB/s eta 0:00:24     |███████████████                 | 29.0 MB 1.5 MB/s eta 0:00:22     |███████████████████▏            | 36.9 MB 39.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiohttp\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/91/1b/9b5da3748ddd924288d9a946a0f48a34b179330d342c6cdeb89683bcf971/aiohttp-3.8.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 69.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/e8/f6/3eccfb530aac90ad1301c582da228e4763f19e719ac8200752a4841b0b2d/fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "\u001b[K     |████████████████████████████████| 166 kB 42.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dill\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/f5/3a/74a29b11cf2cdfcd6ba89c0cecd70b37cd1ba7b77978ce611eb7a146a832/dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[K     |████████████████████████████████| 115 kB 83.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /root/miniconda3/lib/python3.8/site-packages (from datasets==1.18.3->-r requirements.txt (line 1)) (2.28.2)\n",
      "Collecting pyarrow!=4.0.0,>=3.0.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/02/5c/f09c306afe53ed9868e648313707db9893bb19dfdd7666ea043d4e101314/pyarrow-14.0.0-cp38-cp38-manylinux_2_28_x86_64.whl (38.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 38.1 MB 13.6 MB/s eta 0:00:011     |████████████                    | 14.3 MB 2.7 MB/s eta 0:00:09\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/ad/80/8fc9a4d76b259c901f2c85ed10f330a8fb51993a577bddfd53a852595e12/xxhash-3.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[K     |████████████████████████████████| 194 kB 29.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.1.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/ef/b5/b6107bd65fa4c96fdf00e4733e2fe5729bb9e5e09997f63074bb43d3ab28/huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
      "\u001b[K     |████████████████████████████████| 301 kB 33.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /root/miniconda3/lib/python3.8/site-packages (from datasets==1.18.3->-r requirements.txt (line 1)) (23.0)\n",
      "Collecting multiprocess\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/c2/a6/c5cb599d917904878f220a4dbdfdcc4ef291dd3956c35b3b0dc6fc42fb6d/multiprocess-0.70.15-py38-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 25.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: psutil>=5.6.0 in /root/miniconda3/lib/python3.8/site-packages (from gpustat==1.1->-r requirements.txt (line 3)) (5.9.4)\n",
      "Collecting blessed>=1.17.1\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/76/98/584f211c3a4bb38f2871fa937ee0cc83c130de50c955d6c7e2334dbf4acb/blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 57.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-ml-py>=11.450.129\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/a8/10/35b88b64d76aac88ae6b39208827ac0e2a4a2d78f3f2159882efefcad7fd/nvidia_ml_py-12.535.133-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: importlib-resources in /root/miniconda3/lib/python3.8/site-packages (from hydra-core==1.1.1->-r requirements.txt (line 4)) (5.12.0)\n",
      "Collecting antlr4-python3-runtime==4.8\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/56/02/789a0bddf9c9b31b14c3e79ec22b9656185a803dc31c15f006f9855ece0d/antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
      "\u001b[K     |████████████████████████████████| 112 kB 43.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /root/miniconda3/lib/python3.8/site-packages (from importlib-metadata==6.3.0->-r requirements.txt (line 6)) (3.15.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /root/miniconda3/lib/python3.8/site-packages (from matplotlib==3.5.1->-r requirements.txt (line 7)) (9.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /root/miniconda3/lib/python3.8/site-packages (from matplotlib==3.5.1->-r requirements.txt (line 7)) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /root/miniconda3/lib/python3.8/site-packages (from matplotlib==3.5.1->-r requirements.txt (line 7)) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /root/miniconda3/lib/python3.8/site-packages (from matplotlib==3.5.1->-r requirements.txt (line 7)) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /root/miniconda3/lib/python3.8/site-packages (from matplotlib==3.5.1->-r requirements.txt (line 7)) (4.39.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /root/miniconda3/lib/python3.8/site-packages (from matplotlib==3.5.1->-r requirements.txt (line 7)) (3.0.9)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/79/33/67c4ed826f5227655225c3feaaecd15afb8453e827334ddae95a7fba07ac/regex-2023.10.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\n",
      "\u001b[K     |████████████████████████████████| 776 kB 21.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting click\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 28.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[K     |████████████████████████████████| 302 kB 38.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /root/miniconda3/lib/python3.8/site-packages (from pandas==1.4.0->-r requirements.txt (line 11)) (2022.7.1)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: torchvision in /root/miniconda3/lib/python3.8/site-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 15)) (0.15.2+cu118)\n",
      "Collecting sentencepiece\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/c9/58/4fbd3f33a38c9809fedf57bbef7e086b9909d6807148f35d68c0c90896d3/sentencepiece-0.1.99-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 15.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in /root/miniconda3/lib/python3.8/site-packages (from torch==2.0.1->-r requirements.txt (line 17)) (3.10.0)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/lib/python3.8/site-packages (from torch==2.0.1->-r requirements.txt (line 17)) (3.0)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/lib/python3.8/site-packages (from torch==2.0.1->-r requirements.txt (line 17)) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /root/miniconda3/lib/python3.8/site-packages (from torch==2.0.1->-r requirements.txt (line 17)) (2.0.0)\n",
      "Requirement already satisfied: typing-extensions in /root/miniconda3/lib/python3.8/site-packages (from torch==2.0.1->-r requirements.txt (line 17)) (4.5.0)\n",
      "Requirement already satisfied: sympy in /root/miniconda3/lib/python3.8/site-packages (from torch==2.0.1->-r requirements.txt (line 17)) (1.11.1)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/7d/cb/878e746f52e3c55312c34d89a3a80f1b2db59f5293457a75cbc99c82a27a/safetensors-0.4.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 20.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting accelerate\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/13/9e/ee987874058f2d93006961f6ff49e0bcb60ab9c26709ebe06bfa8707a4d8/accelerate-0.24.1-py3-none-any.whl (261 kB)\n",
      "\u001b[K     |████████████████████████████████| 261 kB 21.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting portalocker\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/17/9e/87671efcca80ba6203811540ed1f9c0462c1609d2281d7b7f53cef05da3d/portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: cmake in /root/miniconda3/lib/python3.8/site-packages (from triton==2.0.0->torch==2.0.1->-r requirements.txt (line 17)) (3.26.0)\n",
      "Requirement already satisfied: lit in /root/miniconda3/lib/python3.8/site-packages (from triton==2.0.0->torch==2.0.1->-r requirements.txt (line 17)) (15.0.7)\n",
      "Requirement already satisfied: six>=1.9.0 in /root/miniconda3/lib/python3.8/site-packages (from blessed>=1.17.1->gpustat==1.1->-r requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in /root/miniconda3/lib/python3.8/site-packages (from blessed>=1.17.1->gpustat==1.1->-r requirements.txt (line 3)) (0.2.6)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /root/miniconda3/lib/python3.8/site-packages (from aiohttp->datasets==1.18.3->-r requirements.txt (line 1)) (3.1.0)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/c4/0c/7898c35ca4945fdd416e1dadeda985cc391e4f9298ae5e71c3a5cd88e82d/yarl-1.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (266 kB)\n",
      "\u001b[K     |████████████████████████████████| 266 kB 19.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/0b/36/c276486f89bee9098332710af2207344f360c6c6f104a4931a7566039b1d/frozenlist-1.4.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (220 kB)\n",
      "\u001b[K     |████████████████████████████████| 220 kB 18.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /root/miniconda3/lib/python3.8/site-packages (from aiohttp->datasets==1.18.3->-r requirements.txt (line 1)) (22.2.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/fe/0c/8469202f8f4b0e65816f91c3febc4bda7316c995b59ecdf3b15c574f7a24/multidict-6.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
      "\u001b[K     |████████████████████████████████| 121 kB 11.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /root/miniconda3/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.18.3->-r requirements.txt (line 1)) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.18.3->-r requirements.txt (line 1)) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /root/miniconda3/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.18.3->-r requirements.txt (line 1)) (1.26.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/lib/python3.8/site-packages (from jinja2->torch==2.0.1->-r requirements.txt (line 17)) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /root/miniconda3/lib/python3.8/site-packages (from sympy->torch==2.0.1->-r requirements.txt (line 17)) (1.3.0)\n",
      "Building wheels for collected packages: gpustat, sentence-transformers, iopath, antlr4-python3-runtime\n",
      "  Building wheel for gpustat (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gpustat: filename=gpustat-1.1-py3-none-any.whl size=26391 sha256=3d97dfd1a303aab6f20b404a39ac2071f2e9acf8134e5e8ff5b283a201c17aba\n",
      "  Stored in directory: /root/.cache/pip/wheels/7b/9b/d1/790d1a767e50ada741645f5beae025302e6376db94433f9c8a\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125918 sha256=0aa2c7d0130ba7565a7344b8d2049cbcc1e708752a1f45a5c20ed4bb4a76c7d3\n",
      "  Stored in directory: /root/.cache/pip/wheels/32/f4/41/b0ce5d097de122e65a768e379e68d788507c787c6d8566e561\n",
      "  Building wheel for iopath (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31543 sha256=d64555997db03bb571719a6323af4d29321f4c34076c944d082b5ebe1d034adf\n",
      "  Stored in directory: /root/.cache/pip/wheels/4d/86/65/883a6b23a2c5b7af517ceef6904da305a80452257ca563e1e4\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=b60c0f0d25e3aeb7dd457864943126636d0c5599047b64754e18352f7bc10699\n",
      "  Stored in directory: /root/.cache/pip/wheels/84/c8/1d/50fa2a363062ce625b47af89c410bd77f339f1d59682c091c9\n",
      "Successfully built gpustat sentence-transformers iopath antlr4-python3-runtime\n",
      "Installing collected packages: multidict, frozenlist, yarl, tqdm, numpy, fsspec, async-timeout, aiosignal, tokenizers, threadpoolctl, scipy, safetensors, regex, joblib, huggingface-hub, dill, click, antlr4-python3-runtime, aiohttp, xxhash, transformers, sentencepiece, scikit-learn, pyarrow, portalocker, pandas, omegaconf, nvidia-ml-py, nltk, multiprocess, blessed, accelerate, timm, sentence-transformers, peft, opencv-python, openai, matplotlib, iopath, importlib-metadata, hydra-core, higher, gpustat, einops, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.61.2\n",
      "    Uninstalling tqdm-4.61.2:\n",
      "      Successfully uninstalled tqdm-4.61.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.2\n",
      "    Uninstalling numpy-1.24.2:\n",
      "      Successfully uninstalled numpy-1.24.2\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.7.1\n",
      "    Uninstalling matplotlib-3.7.1:\n",
      "      Successfully uninstalled matplotlib-3.7.1\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 6.0.0\n",
      "    Uninstalling importlib-metadata-6.0.0:\n",
      "      Successfully uninstalled importlib-metadata-6.0.0\n",
      "Successfully installed accelerate-0.24.1 aiohttp-3.8.6 aiosignal-1.3.1 antlr4-python3-runtime-4.8 async-timeout-4.0.3 blessed-1.20.0 click-8.1.7 datasets-1.18.3 dill-0.3.7 einops-0.4.0 frozenlist-1.4.0 fsspec-2023.10.0 gpustat-1.1 higher-0.2.1 huggingface-hub-0.18.0 hydra-core-1.1.1 importlib-metadata-6.3.0 iopath-0.1.10 joblib-1.3.2 matplotlib-3.5.1 multidict-6.0.4 multiprocess-0.70.15 nltk-3.6.5 numpy-1.22.1 nvidia-ml-py-12.535.133 omegaconf-2.1.1 openai-0.27.9 opencv-python-4.8.0.76 pandas-1.4.0 peft-0.5.0 portalocker-2.8.2 pyarrow-14.0.0 regex-2023.10.3 safetensors-0.4.0 scikit-learn-1.0.2 scipy-1.7.3 sentence-transformers-2.2.2 sentencepiece-0.1.99 threadpoolctl-3.2.0 timm-0.9.7 tokenizers-0.13.3 tqdm-4.62.3 transformers-4.30.1 xxhash-3.4.1 yarl-1.9.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Collecting fairscale\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/c1/08/b3334d7b543ac10dcb129cef4f84723ab696725512f18d69ab3a784b0bf5/fairscale-0.4.13.tar.gz (266 kB)\n",
      "\u001b[K     |████████████████████████████████| 266 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.0 in /root/miniconda3/lib/python3.8/site-packages (from fairscale) (1.22.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /root/miniconda3/lib/python3.8/site-packages (from fairscale) (2.0.1+cu118)\n",
      "Requirement already satisfied: typing-extensions in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.8.0->fairscale) (4.5.0)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.8.0->fairscale) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.8.0->fairscale) (2.0.0)\n",
      "Requirement already satisfied: sympy in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.8.0->fairscale) (1.11.1)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.8.0->fairscale) (3.0)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.8.0->fairscale) (3.10.0)\n",
      "Requirement already satisfied: cmake in /root/miniconda3/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.8.0->fairscale) (3.26.0)\n",
      "Requirement already satisfied: lit in /root/miniconda3/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.8.0->fairscale) (15.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/lib/python3.8/site-packages (from jinja2->torch>=1.8.0->fairscale) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /root/miniconda3/lib/python3.8/site-packages (from sympy->torch>=1.8.0->fairscale) (1.3.0)\n",
      "Building wheels for collected packages: fairscale\n",
      "  Building wheel for fairscale (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332106 sha256=37f1e3c2114ca6381cd63cb5964f557bda63a82700c91b393b2c7f2977e09f3d\n",
      "  Stored in directory: /root/.cache/pip/wheels/56/e3/09/318000c05585cfa7703be49d01f917ec1f461fb1b88fec6256\n",
      "Successfully built fairscale\n",
      "Installing collected packages: fairscale\n",
      "Successfully installed fairscale-0.4.13\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118\n",
    "%pip install -r requirements.txt\n",
    "%pip install fairscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to [download the dataset](https://huggingface.co/EleutherAI/gpt-j-6b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mhugging_cache\u001b[00m\n",
      "└── \u001b[01;34mgpt-j-6B\u001b[00m\n",
      "    ├── added_tokens.json\n",
      "    ├── config.json\n",
      "    ├── merges.txt\n",
      "    ├── pytorch_model.bin\n",
      "    ├── special_tokens_map.json\n",
      "    ├── tokenizer.json\n",
      "    ├── tokenizer_config.json\n",
      "    └── vocab.json\n",
      "\n",
      "1 directory, 8 files\n"
     ]
    }
   ],
   "source": [
    "!tree hugging_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config Method Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alg_name: \"ROME\"\n",
      "model_name: \"./hugging_cache/gpt-j-6B\"\n",
      "stats_dir: \"./data/stats\"\n",
      "device: 3\n",
      "layers: [5]\n",
      "fact_token: \"subject_last\"\n",
      "v_num_grad_steps: 20\n",
      "v_lr: 5e-1\n",
      "v_loss_layer: 27\n",
      "v_weight_decay: 0.5\n",
      "clamp_norm_factor: 4\n",
      "kl_factor: 0.0625\n",
      "mom2_adjustment: false\n",
      "context_template_length_params: [[5, 10], [10, 10]]\n",
      "rewrite_module_tmp: \"transformer.h.{}.mlp.fc_out\"\n",
      "layer_module_tmp: \"transformer.h.{}\"\n",
      "mlp_module_tmp: \"transformer.h.{}.mlp\"\n",
      "attn_module_tmp: \"transformer.h.{}.attn\"\n",
      "ln_f_module: \"transformer.ln_f\"\n",
      "lm_head_module: \"lm_head\"\n",
      "mom2_dataset: \"wikipedia\"\n",
      "mom2_n_samples: 100000\n",
      "mom2_dtype: \"float32\"\n",
      "model_parallel: false\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat hparams/ROME/gpt-j-6B.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules & Run\n",
    "\n",
    "### Edit GPT-J-6B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:16:13,701 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "11/08/2023 16:16:13 - INFO - easyeditor.editors.editor -   Instantiating model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing ROME algorithm for the update: [Who was the designer of Lahti Town Hall?] -> [ Alfred Lahti]\n",
      "Cached context templates ['{}', 'The present invention is directed. {}', 'The present invention relates to. {}', 'Therefore, it would be. {}', 'Therefore, we have a. {}', 'Because I was in a. {}', 'Because the majority of our. {}', 'I am so excited!. {}', 'I have a question,. {}', 'You are here . {}', 'You have been selected to. {}', 'The present invention relates to a method for manufacturing a. {}', 'The present invention relates to an apparatus for the manufacture. {}', 'Therefore, we have to make sure that we don. {}', 'Therefore, the court finds that the plaintiff has failed. {}', 'Because of its high sensitivity, high resolution and good. {}', 'Because the majority of people in the world today are. {}', 'I[NTRODUCTION].small. {}', 'I[NTRODUCTION].small. {}', 'You are currently viewing the old forums. We have. {}', 'You\\'re a liar,\" she said. \"You. {}']\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Lahti Town Hall\n",
      "Left vector shape: torch.Size([16384])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 8 | Sentence: Who was the designer of Lahti Town Hall? Alfred Lah | Token:  Hall\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 27\n",
      "Recording initial value of v*\n",
      "loss 4.871 = 4.871 + 0.0 + 0.0 avg prob of [ Alfred Lahti] 0.00904875062406063\n",
      "loss 3.612 = 3.57 + 0.01 + 0.033 avg prob of [ Alfred Lahti] 0.030306831002235413\n",
      "loss 2.422 = 2.338 + 0.032 + 0.051 avg prob of [ Alfred Lahti] 0.09839092940092087\n",
      "loss 1.781 = 1.691 + 0.025 + 0.064 avg prob of [ Alfred Lahti] 0.1851992905139923\n",
      "loss 0.441 = 0.34 + 0.025 + 0.076 avg prob of [ Alfred Lahti] 0.7175434827804565\n",
      "loss 0.209 = 0.1 + 0.022 + 0.087 avg prob of [ Alfred Lahti] 0.9090613722801208\n",
      "loss 0.115 = 0.009 + 0.016 + 0.09 avg prob of [ Alfred Lahti] 0.991016685962677\n",
      "loss 0.108 = 0.003 + 0.014 + 0.09 avg prob of [ Alfred Lahti] 0.9967304468154907\n",
      "loss 0.107 = 0.002 + 0.014 + 0.09 avg prob of [ Alfred Lahti] 0.9975053668022156\n",
      "loss 0.107 = 0.002 + 0.015 + 0.09 avg prob of [ Alfred Lahti] 0.9975295662879944\n",
      "loss 0.108 = 0.003 + 0.015 + 0.09 avg prob of [ Alfred Lahti] 0.9973660707473755\n",
      "loss 0.108 = 0.003 + 0.015 + 0.09 avg prob of [ Alfred Lahti] 0.9972419142723083\n",
      "loss 0.108 = 0.003 + 0.015 + 0.09 avg prob of [ Alfred Lahti] 0.997273325920105\n",
      "loss 0.107 = 0.003 + 0.014 + 0.09 avg prob of [ Alfred Lahti] 0.9974730610847473\n",
      "loss 0.106 = 0.002 + 0.014 + 0.09 avg prob of [ Alfred Lahti] 0.9977811574935913\n",
      "loss 0.106 = 0.002 + 0.014 + 0.09 avg prob of [ Alfred Lahti] 0.9981198906898499\n",
      "loss 0.105 = 0.002 + 0.013 + 0.09 avg prob of [ Alfred Lahti] 0.9984325170516968\n",
      "loss 0.104 = 0.001 + 0.013 + 0.09 avg prob of [ Alfred Lahti] 0.9986923336982727\n",
      "loss 0.103 = 0.001 + 0.012 + 0.09 avg prob of [ Alfred Lahti] 0.9988945722579956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:17:57,645 - easyeditor.editors.editor - INFO - Execution 0 editing took 21.597137689590454\n",
      "11/08/2023 16:17:57 - INFO - easyeditor.editors.editor -   Execution 0 editing took 21.597137689590454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.103 = 0.001 + 0.012 + 0.09 avg prob of [ Alfred Lahti] 0.9990456104278564\n",
      "Delta norm: 88.73495483398438\n",
      "Change in target norm: 22.18373680114746 to 91.83134460449219 => 69.6476058959961\n",
      "Division Factor: 22.852832794189453\n",
      "Right vector norm: 3.8828864097595215\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['transformer.h.5.mlp.fc_out.weight']\n",
      "New weights successfully inserted into ['transformer.h.5.mlp.fc_out.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:17:57,743 - easyeditor.editors.editor - INFO - Evaluation took 0.09455752372741699\n",
      "11/08/2023 16:17:57 - INFO - easyeditor.editors.editor -   Evaluation took 0.09455752372741699\n",
      "2023-11-08 16:17:57,745 - easyeditor.editors.editor - INFO - 0 editing: Who was the designer of Lahti Town Hall? -> Alfred Lahti  \n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'Who was the designer of Lahti Town Hall?', 'target_new': 'Alfred Lahti', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Lahti Town Hall'}, 'time': 21.597137689590454, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "11/08/2023 16:17:57 - INFO - easyeditor.editors.editor -   0 editing: Who was the designer of Lahti Town Hall? -> Alfred Lahti  \n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'Who was the designer of Lahti Town Hall?', 'target_new': 'Alfred Lahti', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Lahti Town Hall'}, 'time': 21.597137689590454, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing ROME algorithm for the update: [What role does Denny Herzig play in football?] -> [ winger]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Denny Herzig\n",
      "Left vector shape: torch.Size([16384])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: What role does Denny Herzig play in football? | Token: ig\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 27\n",
      "Recording initial value of v*\n",
      "loss 14.686 = 14.686 + 0.0 + 0.0 avg prob of [ winger] 5.603147315014212e-07\n",
      "loss 11.642 = 11.579 + 0.037 + 0.026 avg prob of [ winger] 1.1279879799985792e-05\n",
      "loss 7.085 = 7.003 + 0.043 + 0.038 avg prob of [ winger] 0.0013461933704093099\n",
      "loss 2.889 = 2.242 + 0.599 + 0.048 avg prob of [ winger] 0.11461612582206726\n",
      "loss 0.529 = 0.109 + 0.364 + 0.056 avg prob of [ winger] 0.897243320941925\n",
      "loss 0.337 = 0.026 + 0.247 + 0.064 avg prob of [ winger] 0.974382758140564\n",
      "loss 0.28 = 0.014 + 0.193 + 0.072 avg prob of [ winger] 0.9858134984970093\n",
      "loss 0.275 = 0.012 + 0.183 + 0.08 avg prob of [ winger] 0.9880332946777344\n",
      "loss 0.272 = 0.011 + 0.18 + 0.081 avg prob of [ winger] 0.9887214303016663\n",
      "loss 0.269 = 0.011 + 0.177 + 0.081 avg prob of [ winger] 0.9889510273933411\n",
      "loss 0.265 = 0.011 + 0.173 + 0.081 avg prob of [ winger] 0.9892476797103882\n",
      "loss 0.26 = 0.01 + 0.169 + 0.081 avg prob of [ winger] 0.9899439215660095\n",
      "loss 0.254 = 0.009 + 0.165 + 0.081 avg prob of [ winger] 0.9910802841186523\n",
      "loss 0.248 = 0.008 + 0.16 + 0.081 avg prob of [ winger] 0.9924570918083191\n",
      "loss 0.239 = 0.006 + 0.153 + 0.081 avg prob of [ winger] 0.9938138723373413\n",
      "loss 0.227 = 0.005 + 0.142 + 0.081 avg prob of [ winger] 0.9949751496315002\n",
      "loss 0.208 = 0.004 + 0.123 + 0.081 avg prob of [ winger] 0.9958772659301758\n",
      "loss 0.171 = 0.003 + 0.087 + 0.081 avg prob of [ winger] 0.9965192675590515\n",
      "loss 0.122 = 0.003 + 0.039 + 0.081 avg prob of [ winger] 0.9969202876091003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:18:14,186 - easyeditor.editors.editor - INFO - Execution 1 editing took 16.43937587738037\n",
      "11/08/2023 16:18:14 - INFO - easyeditor.editors.editor -   Execution 1 editing took 16.43937587738037\n",
      "2023-11-08 16:18:14,277 - easyeditor.editors.editor - INFO - Evaluation took 0.08838653564453125\n",
      "11/08/2023 16:18:14 - INFO - easyeditor.editors.editor -   Evaluation took 0.08838653564453125\n",
      "2023-11-08 16:18:14,279 - easyeditor.editors.editor - INFO - 1 editing: What role does Denny Herzig play in football? -> winger  \n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'What role does Denny Herzig play in football?', 'target_new': 'winger', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Denny Herzig'}, 'time': 16.43937587738037, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "11/08/2023 16:18:14 - INFO - easyeditor.editors.editor -   1 editing: What role does Denny Herzig play in football? -> winger  \n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'What role does Denny Herzig play in football?', 'target_new': 'winger', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Denny Herzig'}, 'time': 16.43937587738037, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.105 = 0.003 + 0.021 + 0.081 avg prob of [ winger] 0.9971562623977661\n",
      "Delta norm: 99.32398986816406\n",
      "Change in target norm: 24.83099937438965 to 103.1259765625 => 78.29497528076172\n",
      "Division Factor: 22.630273818969727\n",
      "Right vector norm: 4.3889875411987305\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['transformer.h.5.mlp.fc_out.weight']\n",
      "New weights successfully inserted into ['transformer.h.5.mlp.fc_out.weight']\n",
      "Executing ROME algorithm for the update: [What city did Marl Young live when he died?] -> [ New Orleans]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Marl Young\n",
      "Left vector shape: torch.Size([16384])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 5 | Sentence: What city did Marl Young live when he died? New | Token:  Young\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 27\n",
      "Recording initial value of v*\n",
      "loss 3.539 = 3.539 + 0.0 + 0.0 avg prob of [ New Orleans] 0.030853087082505226\n",
      "loss 1.923 = 1.894 + 0.016 + 0.014 avg prob of [ New Orleans] 0.15223895013332367\n",
      "loss 0.629 = 0.572 + 0.035 + 0.021 avg prob of [ New Orleans] 0.5691357851028442\n",
      "loss 0.209 = 0.15 + 0.031 + 0.028 avg prob of [ New Orleans] 0.8609225749969482\n",
      "loss 0.096 = 0.042 + 0.02 + 0.034 avg prob of [ New Orleans] 0.9589771032333374\n",
      "loss 0.066 = 0.011 + 0.016 + 0.039 avg prob of [ New Orleans] 0.9892451763153076\n",
      "loss 0.068 = 0.005 + 0.02 + 0.044 avg prob of [ New Orleans] 0.9951686263084412\n",
      "loss 0.073 = 0.003 + 0.022 + 0.048 avg prob of [ New Orleans] 0.9966432452201843\n",
      "loss 0.076 = 0.003 + 0.022 + 0.051 avg prob of [ New Orleans] 0.9972995519638062\n",
      "loss 0.078 = 0.002 + 0.021 + 0.055 avg prob of [ New Orleans] 0.9976487755775452\n",
      "loss 0.08 = 0.002 + 0.021 + 0.057 avg prob of [ New Orleans] 0.9978583455085754\n",
      "loss 0.081 = 0.002 + 0.021 + 0.058 avg prob of [ New Orleans] 0.9980762600898743\n",
      "loss 0.081 = 0.002 + 0.021 + 0.058 avg prob of [ New Orleans] 0.9982889294624329\n",
      "loss 0.08 = 0.002 + 0.02 + 0.058 avg prob of [ New Orleans] 0.9984672665596008\n",
      "loss 0.079 = 0.001 + 0.019 + 0.058 avg prob of [ New Orleans] 0.9986180067062378\n",
      "loss 0.078 = 0.001 + 0.018 + 0.058 avg prob of [ New Orleans] 0.9987452626228333\n",
      "loss 0.077 = 0.001 + 0.017 + 0.058 avg prob of [ New Orleans] 0.9988517165184021\n",
      "loss 0.076 = 0.001 + 0.017 + 0.058 avg prob of [ New Orleans] 0.9989395141601562\n",
      "loss 0.076 = 0.001 + 0.017 + 0.058 avg prob of [ New Orleans] 0.9990110993385315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:18:30,851 - easyeditor.editors.editor - INFO - Execution 2 editing took 16.56955099105835\n",
      "11/08/2023 16:18:30 - INFO - easyeditor.editors.editor -   Execution 2 editing took 16.56955099105835\n",
      "2023-11-08 16:18:30,941 - easyeditor.editors.editor - INFO - Evaluation took 0.0885305404663086\n",
      "11/08/2023 16:18:30 - INFO - easyeditor.editors.editor -   Evaluation took 0.0885305404663086\n",
      "2023-11-08 16:18:30,943 - easyeditor.editors.editor - INFO - 2 editing: What city did Marl Young live when he died? -> New Orleans  \n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What city did Marl Young live when he died?', 'target_new': 'New Orleans', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Marl Young'}, 'time': 16.56955099105835, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "11/08/2023 16:18:30 - INFO - easyeditor.editors.editor -   2 editing: What city did Marl Young live when he died? -> New Orleans  \n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What city did Marl Young live when he died?', 'target_new': 'New Orleans', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Marl Young'}, 'time': 16.56955099105835, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.076 = 0.001 + 0.017 + 0.058 avg prob of [ New Orleans] 0.9990687966346741\n",
      "Delta norm: 136.99810791015625\n",
      "Change in target norm: 34.24952697753906 to 142.47154235839844 => 108.22201538085938\n",
      "Division Factor: 20.053741455078125\n",
      "Right vector norm: 6.83154821395874\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['transformer.h.5.mlp.fc_out.weight']\n",
      "New weights successfully inserted into ['transformer.h.5.mlp.fc_out.weight']\n",
      "[{'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'Who was the designer of Lahti Town Hall?', 'target_new': 'Alfred Lahti', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Lahti Town Hall'}, 'time': 21.597137689590454, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}, {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'What role does Denny Herzig play in football?', 'target_new': 'winger', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Denny Herzig'}, 'time': 16.43937587738037, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}, {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What city did Marl Young live when he died?', 'target_new': 'New Orleans', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Marl Young'}, 'time': 16.56955099105835, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}]\n",
      "<class 'transformers.models.gptj.modeling_gptj.GPTJForCausalLM'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda:3')\n",
    "\n",
    "from easyeditor import BaseEditor\n",
    "from easyeditor import ROMEHyperParams\n",
    "\n",
    "hparams = ROMEHyperParams.from_hparams('./hparams/ROME/gpt-j-6B.yaml')\n",
    "prompts = [\n",
    "    'Who was the designer of Lahti Town Hall?',\n",
    "    'What role does Denny Herzig play in football?',\n",
    "    'What city did Marl Young live when he died?'\n",
    "]\n",
    "target_new = ['Alfred Lahti', 'winger', 'New Orleans']\n",
    "subject = ['Lahti Town Hall', 'Denny Herzig', 'Marl Young']\n",
    "\n",
    "editor = BaseEditor.from_hparams(hparams)\n",
    "metrics, edited_model, _ = editor.edit(\n",
    "    prompts=prompts,\n",
    "    ground_truth=None,\n",
    "    target_new=target_new,\n",
    "    subject=subject,\n",
    "    keep_original_weight=False\n",
    ")\n",
    "print(metrics)\n",
    "print(type(edited_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reliability Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenyao/.conda/envs/easyedit/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Edit Outputs:  ['<|endoftext|>Who was the designer of Lahti Town Hall?\\n\\nThe Town Hall of Lahti', 'What role does Denny Herzig play in football?\\n\\nDenny Herzig is the', 'What city did Marl Young live when he died?\\n\\nMarl Young was born in']\n",
      "Post-Edit Outputs:  ['<|endoftext|>Who was the designer of Lahti Town Hall? Alfred Lahti was the name. He', 'What role does Denny Herzig play in football?\\n\\nDenny is a former New', 'What city did Marl Young live when he died? New Orleans.\\n\\nThe New Orleans']\n"
     ]
    }
   ],
   "source": [
    "# Reliability Test\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GPTJForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('./hugging_cache/gpt-j-6B', cache_dir='./hugging_cache')\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = 'left'\n",
    "\n",
    "correct_prompts = [\n",
    "    'Who was the designer of Lahti Town Hall?',\n",
    "    'What role does Denny Herzig play in football?',\n",
    "    'What city did Marl Young live when he died?'\n",
    "]\n",
    "\n",
    "model = GPTJForCausalLM.from_pretrained('./hugging_cache/gpt-j-6B', cache_dir='./hugging_cache').to(device)\n",
    "batch = tokenizer(correct_prompts, return_tensors='pt', padding=True, max_length=30)\n",
    "\n",
    "pre_edit_outputs = model.generate(\n",
    "    input_ids=batch['input_ids'].to(device),\n",
    "    attention_mask=batch['attention_mask'].to(device),\n",
    "    max_new_tokens=8\n",
    ")\n",
    "\n",
    "post_edit_outputs = edited_model.generate(\n",
    "    input_ids=batch['input_ids'].to(device),\n",
    "    attention_mask=batch['attention_mask'].to(device),\n",
    "    max_new_tokens=8\n",
    ")\n",
    "print('Pre-Edit Outputs: ', [tokenizer.decode(x) for x in pre_edit_outputs.detach().cpu().numpy().tolist()])\n",
    "print('Post-Edit Outputs: ', [tokenizer.decode(x) for x in post_edit_outputs.detach().cpu().numpy().tolist()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalization Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Edit Outputs:  ['<|endoftext|><|endoftext|>Who was the architect behind the design of Lahti Town Hall?\\n\\nThe architect behind the design of', '<|endoftext|>What position does Denny Herzig hold in the sport of football?\\n\\nI’m not sure', 'In what city was Marl Young residing at the time of his death?\\n\\nMarl Young was born in']\n",
      "Post-Edit Outputs:  ['<|endoftext|><|endoftext|>Who was the architect behind the design of Lahti Town Hall? Alfred Lah was a Louisiana native who was', '<|endoftext|>What position does Denny Herzig hold in the sport of football?\\n\\nA\\n\\nNew Orleans Saints', 'In what city was Marl Young residing at the time of his death? New Orleans, Louisiana, USA\\n\\n']\n"
     ]
    }
   ],
   "source": [
    "# Generalization test\n",
    "\n",
    "generation_prompts = [\n",
    "    'Who was the architect behind the design of Lahti Town Hall?',\n",
    "    'What position does Denny Herzig hold in the sport of football?',\n",
    "    'In what city was Marl Young residing at the time of his death?'\n",
    "]\n",
    "\n",
    "batch = tokenizer(generation_prompts , return_tensors='pt', padding=True, max_length=30)\n",
    "\n",
    "pre_edit_outputs = model.generate(\n",
    "    input_ids=batch['input_ids'].to(device),\n",
    "    attention_mask=batch['attention_mask'].to(device),\n",
    "    max_new_tokens=8\n",
    ")\n",
    "post_edit_outputs = edited_model.generate(\n",
    "    input_ids=batch['input_ids'].to(device),\n",
    "    max_new_tokens=8\n",
    ")\n",
    "print('Pre-Edit Outputs: ', [tokenizer.decode(x) for x in pre_edit_outputs.detach().cpu().numpy().tolist()])\n",
    "print('Post-Edit Outputs: ', [tokenizer.decode(x) for x in post_edit_outputs.detach().cpu().numpy().tolist()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locality Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Edit Outputs:  ['<|endoftext|>Who was the designer of Eiffel Tower?\\n\\nThe Eiffel Tower is', '<|endoftext|><|endoftext|><|endoftext|>What role does Messi play in football?\\n\\nThe answer is simple: he', 'What city did Madame Curie live when he died?\\n\\nThe Curies lived in Paris']\n",
      "Post-Edit Outputs:  ['<|endoftext|>Who was the designer of Eiffel Tower?\\n\\nThe Eiffel Tower is', '<|endoftext|><|endoftext|><|endoftext|>What role does Messi play in football?\\n\\nThe New Orleans Saints are a', 'What city did Madame Curie live when he died?\\n\\nThe answer is simple.\\n']\n"
     ]
    }
   ],
   "source": [
    "# Locality test\n",
    "\n",
    "locality_prompts = [\n",
    "    'Who was the designer of Eiffel Tower?',\n",
    "    'What role does Messi play in football?',\n",
    "    'What city did Madame Curie live when he died?'\n",
    "]\n",
    "\n",
    "batch = tokenizer(locality_prompts, return_tensors='pt', padding=True, max_length=30)\n",
    "\n",
    "pre_edit_outputs = model.generate(\n",
    "    input_ids=batch['input_ids'].to(device),\n",
    "    attention_mask=batch['attention_mask'].to(device),\n",
    "    max_new_tokens=8\n",
    ")\n",
    "post_edit_outputs = edited_model.generate(\n",
    "    input_ids=batch['input_ids'].to(device),\n",
    "    attention_mask=batch['attention_mask'].to(device),\n",
    "    max_new_tokens=8\n",
    ")\n",
    "print('Pre-Edit Outputs: ', [tokenizer.decode(x) for x in pre_edit_outputs.detach().cpu().numpy().tolist()])\n",
    "print('Post-Edit Outputs: ', [tokenizer.decode(x) for x in post_edit_outputs.detach().cpu().numpy().tolist()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
