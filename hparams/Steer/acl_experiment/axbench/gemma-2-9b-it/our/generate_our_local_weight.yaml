# === Basic Config ===
alg_name: sft
layers: [20]
use_cache: false

# === Dataset Config ===
exclude_bos: true
max_concepts: 1
max_num_of_examples: null
preference_pairs: ["orig_add"] # use_cmd_to_define
output_length: 512

# === Training Config ===
batch_size: 2 # the actual batch size also needs to multiply with |preference_pairs|
dropout: 0.1
gradient_accumulation_steps: 2
lr: 0.04
n_epochs: 12

weight_decay: 0.00
pos_loss_weight: 1.0    
neg_loss_weight: 0.3      
margin_penalty_weight: 3.5   
ref_loss_weight: 0.0       
margin_threshold: 0.6      

loss_output_dir: null
inference: false

# === Intervention Config ===
intervention_components: "mlp_mid"
intervention_positions: "all"
intervention_positions_dropout: 0.0
intervention_type: "addition" # clamping
intervention_method: "local_weight"
low_rank_dimension: 4

# === Steering Config ===
steering_factors: [0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0] # use_cmd_to_define

steering_prompt_type: "blend_in"
substraction_type: "normal" # normal or null_it_out